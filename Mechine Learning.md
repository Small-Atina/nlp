#### 1.LR（分类模型，判别模型）
+ 用自己的话描述一下LR
+ 为什么LR用sigmoid函数
+ 为什么损失函数使用交叉熵而不用均方差
+ 手推LR参数梯度下降
+ 并行化
+ 如果多分类可以使用LR模型吗？
+ 如果数据不可分怎么办？
+ LR的优缺点
+ LR和线性回归的区别

#### 2.SVM（分类模型，判别模型）
+ 
#### LR和SVM的区别

#### 3.Decision Tree
#### 4.Random Tree
#### 5.GBDT
#### 6.XGboost
#### 7.LightGBM
#### Random和GBDT区别；GBDT和XGboost区别；LightGBM和XGboost的区别

#### 8.KNN(K-近邻)（有监督的分类模型）
+ 分类；有监督；有label，没有专门的训练过程
+ K值含义 - 对于一个样本X，要给它分类，首先从数据集中，在X附近找离它最近的K个数据点，将它划分为归属于类别最多的一类
+ 算法流程

#### 9.K-means（无监督的聚类模型）
+ 算法目标：将输入数据划分为k个聚类
+ 聚类算法；非监督模型；无label，有明显的训练过程
+ K值含义- K是事先设定的数字，将数据集分为K个簇，需要依靠人的先验知识
+ 算法流程
#### KNN和K-means区别

#### 10.HMM
#### 11.CRT

#### 12.Bayes
#### 13.EM

#### 
